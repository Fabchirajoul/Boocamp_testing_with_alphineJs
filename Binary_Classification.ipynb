{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1P8RiakznDIyEa45GVZJ2f1QPGRNbx315",
      "authorship_tag": "ABX9TyOifvMwHMcRIVKrOvuMPhyr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fabchirajoul/Boocamp_testing_with_alphineJs/blob/Main/Binary_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREPARING OUR ENVIRONMENT"
      ],
      "metadata": {
        "id": "L0hQ8RpYYoxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This involves the installation of the different libraries which we will be using in the import the different modules from their respective libraries. The most common ones are:\n",
        "\n",
        "1. Dataset: pip install datasets will install the dataset library which is a  convenient and efficient way to access and work with a wide variety of natural language processing (NLP) datasets\n",
        "\n",
        "2. Transformers: pip install transformer: It provides a collection of pre-trained models, tokenizers, and utilities that make it easy for researchers and developers to work with state-of-the-art models in NLP\n",
        "\n",
        "3. pip install accelerate -U: The -U stands for upgrade which will upgrade the accelerate python package if exist if not it installs the latest version.It provides a set of optimized libraries and tools to enhance the performance of various Python packages, such as NumPy, PyTorch, and TensorFlow, when running on NVIDIA GPUs\n",
        "\n",
        "NB: Once these packages have been installed, please make sure to restart your kernel session by clicking on the Runtime  tab and then select \"Restart session and run all\""
      ],
      "metadata": {
        "id": "DSmhFi8tYt6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install accelerate -U"
      ],
      "metadata": {
        "id": "ep9XqLA1vp9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install transformers"
      ],
      "metadata": {
        "id": "I9LE7M0vYhYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install datasets"
      ],
      "metadata": {
        "id": "V1Q3lapCbDCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the neccessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "\n",
        "# This is where point 3 above comes in handy. At times, our CPU becomes limited to process and train our model when the data involved is very huge.\n",
        "# In such a case, it is adviceable to use GPU (Graphics Processing Unit) which is why we ran the command pip install accelerate -U\n",
        "# In the case of the line code below, we are saying that if GPU is installed on the device, then it should be the preferred graphics otherwise, let the\n",
        "# let the CPU be the graphic of choice to use in training the model.\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "ZV9_LLw-QwYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LOADING OUR DATASET"
      ],
      "metadata": {
        "id": "cfTMeSRZcS3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Fine tuning ClimateBert Environmental Claims CSV UTF (3).csv')\n",
        "\n",
        "# df.head() will print the first 10 entries of our dataset. By default, it will print the first 5 unless otherwise the number of\n",
        "# records we want is specified which which in our case is 10. df.tail(10) will print the last 10 rows of our dataset\n",
        "print(\"This is the first 10 entries of our dataset\\n\\n\\n\", df.head(10))\n",
        "# print(\"This is the last 10 entries of our dataset\", df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QufuPnJvuoD",
        "outputId": "36bcfb3b-7acb-4195-8cdd-0200112ea60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the first 10 entries of our dataset\n",
            "\n",
            "\n",
            "                                                 text  label\n",
            "0  So it's going to be gradual but to get to a 55...      0\n",
            "1  Even so, we plan to meet our sales and profit ...      0\n",
            "2  In Europe, all of our pulp and paper mills fal...      0\n",
            "3  The integration of fuel (upstream and procurem...      0\n",
            "4  During Capital Markets Day 2020, Hydro announc...      0\n",
            "5  John, I know you want to add anything at a hig...      0\n",
            "6  I think all businesses have made their commitm...      0\n",
            "7  Like as an example, for 2 decades, we have had...      0\n",
            "8  To this end, Eiffage Route introduced a roadma...      0\n",
            "9  And as you saw, we -- in the 2.7 agreement -- ...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"This is the last 10 entries of our dataset\\n\\n\\n\", df.tail(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLXaxV1cgu5R",
        "outputId": "27532315-cb37-4ffe-8def-4cc71699e43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the last 10 entries of our dataset\n",
            "\n",
            "\n",
            "                                                   text  label\n",
            "387  American Water has committed to reducing our G...      1\n",
            "388  In 2018, we set a goal to have 2-3% of our US ...      1\n",
            "389  In the beginning of 2021, we announced the int...      1\n",
            "390  In 2020 we initiated our third multi-year envi...      1\n",
            "391  We track a variety of climate-related metrics ...      1\n",
            "392  AMP recognises that it has a corporate respons...      1\n",
            "393  This target is a combined  target for all 5 fo...      1\n",
            "394  This target reflects the ambition of the forme...      1\n",
            "395  This Abs3 target is a year-by-year target in c...      1\n",
            "396  In FY20, we reduced GHG emissions by 14% (131,...      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It is common practice in machine learning to know the shape of our dataset which will come in handy when we do the\n",
        "# train, test split when building our model.\n",
        "\n",
        "\n",
        "\n",
        "print(\"The shape of our dataset is:\", df.shape)\n",
        "print(\"The columns in our dataset are:\", df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTknSGU-RICl",
        "outputId": "79fa9aaa-873a-40b2-9508-d0c6a0612240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of our dataset is: (397, 2)\n",
            "The columns in our dataset are: Index(['text', 'label'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Always make it a practice to know the basic information about your data before you encode. Computer understands just integers not\n",
        "# characters. Having the information about your dataset will enable you to know which column to encode into what the computer will understand.\n",
        "\n",
        "# with df.info(), we will see that the text column comprises of objects and as such needs to be encoded into integers.\n",
        "# The column label comprises of integers and as such we don't need to encode since its already in a format that can be understood by the computer.\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRFDJZ4uWY8f",
        "outputId": "44618e2d-f855-4c6c-aca9-2560064d0412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 397 entries, 0 to 396\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    397 non-null    object\n",
            " 1   label   397 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 6.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not neccessary but then also important to have a description of your dataset to know how they are skewed.\n",
        "\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "IBXTDhEpWc0s",
        "outputId": "a113c283-950c-4592-b318-e4f8f924f8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            label\n",
              "count  397.000000\n",
              "mean     0.501259\n",
              "std      0.500629\n",
              "min      0.000000\n",
              "25%      0.000000\n",
              "50%      1.000000\n",
              "75%      1.000000\n",
              "max      1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43d5b750-2869-441b-aa38-e2ecaed089cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>397.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.501259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.500629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43d5b750-2869-441b-aa38-e2ecaed089cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43d5b750-2869-441b-aa38-e2ecaed089cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43d5b750-2869-441b-aa38-e2ecaed089cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-87898b7d-5b2f-4122-ab9b-8e19dcc1d64f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87898b7d-5b2f-4122-ab9b-8e19dcc1d64f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-87898b7d-5b2f-4122-ab9b-8e19dcc1d64f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check class distribution\n",
        "print(df['label'].value_counts(normalize = True))\n",
        "# print(df['text'].value_counts(normalize = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXJx-7EQRMG7",
        "outputId": "3a0bdca2-a1bb-453f-9ced-6a472f20f87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    0.501259\n",
            "0    0.498741\n",
            "Name: label, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if there are repetition of entries in our text column to aid us during encoding so that we don't give different encoding to the same data\n",
        "# Based on our dataset, there are no repitition.\n",
        "\n",
        "df.select_dtypes(include=\"object\").nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tis-88IKh-Rz",
        "outputId": "1b2f4819-89f7-4572-a48a-d6339c40f231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text    389\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split train dataset into train, validation and test sets"
      ],
      "metadata": {
        "id": "JSMo-jvwRQuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'],\n",
        "                                                                    random_state=42,\n",
        "                                                                    test_size=0.2,\n",
        "                                                                    stratify=df['label'])\n"
      ],
      "metadata": {
        "id": "89YPt8FGRT8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The shape of of training text (train_text) is:\", train_text.shape)\n",
        "print(\"The shape of of training text (temp_text) is:\", temp_text.shape)\n",
        "print(\"The shape of of testing label size (train_label) is:\", train_labels.shape)\n",
        "print(\"The shape of of training label (temp_labels)  is:\", temp_labels.shape)\n",
        "print(\"The total should give us the total number of rows in our dataset\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afz1qRUokz4J",
        "outputId": "71b8a3bd-3cc0-4be5-c711-7b129867e0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of of training text (train_text) is: (317,)\n",
            "The shape of of training text (temp_text) is: (80,)\n",
            "The shape of of testing label size (train_label) is: (317,)\n",
            "The shape of of training label (temp_labels)  is: (80,)\n",
            "The total should give us the total number of rows in our dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We have divided the available data into training and testing with 80% being our training data and 20% being our testing data\n",
        "\n",
        "# It is further expected of us to divide the training amount into testing and  validation so that we know exactly how much data has been allocated for\n",
        "# training and validation\n",
        "\n",
        "\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
        "                                                                random_state=2024,\n",
        "                                                                test_size=0.8,\n",
        "                                                                stratify=temp_labels)"
      ],
      "metadata": {
        "id": "uRHJhuEzmXbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The shape of of test text of our testing data which 80% of training data (79) is:\", val_text.shape)\n",
        "print(\"The shape of of test text of our testing data which 80% of of training data (318) is:\", test_text.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2XzxgCTmZSm",
        "outputId": "5cba585c-4412-478a-fb61-018ef471b7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of of test text of our testing data which 80% of training data (79) is: (16,)\n",
            "The shape of of test text of our testing data which 80% of of training data (318) is: (64,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " We are done with splitting and data analysis of our dataset, It suffices that we call tokenizer to encode our split data set. We could have tokenize first before splitting which ever way we decide to go about it would still end  in the same  result."
      ],
      "metadata": {
        "id": "vX2cfUeNvwDU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import BERT Model and BERT Tokenizer"
      ],
      "metadata": {
        "id": "21fUeqvkRvg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import BERT-base pretrained model\n",
        "\n",
        "# There are different tokenizers which can be used from the transformer library such as AutoTokenizer, BertTokenizerFast etc\n",
        "# Which ever one we use would still encode the text rows into machine understandable  data for fine tuning our pretained model from our checkpoint of choice.\n",
        "\n",
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Alternatively, using the automodel tokenizer would still work i.e.\n",
        "\n",
        "# from transformers import AutoTokenizer\n",
        "# bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "\n",
        "# # Load the BERT tokenizer\n",
        "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRa6Zw2iRxPD",
        "outputId": "5a468c8f-13c0-43be-a9ed-2378443b5c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample data\n",
        "text = [\"So it's going to be gradual but to get to a 55% by the end of the year or for the year, we're starting at a place that is 56.7%.\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ],
      "metadata": {
        "id": "yz_Sju3OR_G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output\n",
        "print(sent_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J66kDmyiSB8s",
        "outputId": "d253e501-5dcc-49f5-b37a-1dba9d166613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 2061, 2009, 1005, 1055, 2183, 2000, 2022, 16612, 2021, 2000, 2131, 2000, 1037, 4583, 1003, 2011, 1996, 2203, 1997, 1996, 2095, 2030, 2005, 1996, 2095, 1010, 2057, 1005, 2128, 3225, 2012, 1037, 2173, 2008, 2003, 5179, 1012, 1021, 1003, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "ULBSoXT2SJrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "XjALpbLORzqC",
        "outputId": "b444bd0b-f8a2-47d5-c1ef-3543dd8736b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 50"
      ],
      "metadata": {
        "id": "bie8W0XLS-aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our bert base pretained model, let us now tokenize all our split data which we have carefully allocated a dataframe shape i.e. train_text, val_text, and test_text"
      ],
      "metadata": {
        "id": "ZZHiDbgV1ZuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH7iZJD6TEto",
        "outputId": "f6e8ee70-3f3f-47f8-d0ea-f5faef777b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"This is the tokenizd data for our training dataframe \\n\")\n",
        "tokens_train\n",
        "\n",
        "# We could equally check the tokenized data for the different split dataframe if we want."
      ],
      "metadata": {
        "id": "68ajPaUfXa0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Integer Sequences to Tensors\n",
        "\n",
        "#### Advantages of converting tokens into tensors:\n",
        "##### 1. GPU Acceleration\n",
        "##### 2. Seamless Integration with Deep Learning Libraries\n",
        "##### 3. Batch Processing\n",
        "##### 4. Compatibility with Pre-trained Models\n",
        "##### 5. Automatic Differentiation\n",
        "\n"
      ],
      "metadata": {
        "id": "s0gTgpt-ULX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for train set converting the train tokenzers into tensors\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set converting the validation tokenzers into tensors\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set converting the test tokenzers into tensors\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "metadata": {
        "id": "7gZgXgl-UNjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create DataLoaders\n",
        "\n",
        "### wrap tensors\n",
        "## train_seq:PyTorch tensors representing sequences, , and\n",
        "## train_mask:PyTorch tensors representing attention masks\n",
        "## train_y:PyTorch tensors representing labels\n",
        "## train_data: is now an instance of the TensorDataset class, containing tuples of (train_seq[i], train_mask[i], train_y[i]) for each index i.\n",
        "\n"
      ],
      "metadata": {
        "id": "19GI67tRTMtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "1lteHLKhTN9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Freeze BERT Parameters"
      ],
      "metadata": {
        "id": "0-tAY_mLUgbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "mTPSV0rAUhYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Model Architecture"
      ],
      "metadata": {
        "id": "ep4BimxyUn69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "\n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert\n",
        "\n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "\n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model\n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "\n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "NWpBj8MRUjh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU but in this case CPU since my device does not have the GPU(NDIVIA installed)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "iPJnMCCZUr19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjVTWFP0Xe7b",
        "outputId": "dc32d701-80d7-489c-d7cb-424275390782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find Class Weights"
      ],
      "metadata": {
        "id": "H4EDlkbYXsUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "\n",
        "class_wts = compute_class_weight(class_weight = \"balanced\",classes = np.unique(train_labels),y = train_labels)\n",
        "# class_wts = dict(zip(np.unique(train_labels), class_wts))\n",
        "print(class_wts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMxtdp-zXt7N",
        "outputId": "eb39e658-bcdc-4e86-d3cb-ca20eb153ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.00316456 0.99685535]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We are trying to solve for class imbalance in our dataset with this section of the code.\n",
        "\n",
        "\n",
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights)\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "HKax-48TaUln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning"
      ],
      "metadata": {
        "id": "DDbyNjrcchtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train(\n",
        "    model=model,\n",
        "    train_dataloader=train_dataloader,\n",
        "    optimizer=optimizer,\n",
        "    cross_entropy=cross_entropy,\n",
        "    device=device,\n",
        "    eval_dataset=val_dataloader\n",
        "):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "_aCpfZ5ocgQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "  print(\"\\nEvaluating...\")\n",
        "\n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "\n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "EbFTTY7ycqTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Model Training"
      ],
      "metadata": {
        "id": "cvYGLkJ2c0WP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ADnKeiMc1VZ",
        "outputId": "f089399d-feb2-4c5a-b09b-60e63bf296a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.661\n",
            "Validation Loss: 0.644\n",
            "\n",
            " Epoch 2 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.529\n",
            "Validation Loss: 0.604\n",
            "\n",
            " Epoch 3 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.507\n",
            "Validation Loss: 0.640\n",
            "\n",
            " Epoch 4 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.505\n",
            "Validation Loss: 0.710\n",
            "\n",
            " Epoch 5 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.542\n",
            "Validation Loss: 0.528\n",
            "\n",
            " Epoch 6 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.465\n",
            "Validation Loss: 0.486\n",
            "\n",
            " Epoch 7 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.413\n",
            "Validation Loss: 0.478\n",
            "\n",
            " Epoch 8 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.331\n",
            "Validation Loss: 0.481\n",
            "\n",
            " Epoch 9 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.358\n",
            "Validation Loss: 0.408\n",
            "\n",
            " Epoch 10 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.362\n",
            "Validation Loss: 0.414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1USGTntS3TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c52be408-e616-407f-e711-cb2227a4446a"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.318\n",
            "Validation Loss: 0.600\n",
            "\n",
            " Epoch 2 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.330\n",
            "Validation Loss: 0.377\n",
            "\n",
            " Epoch 3 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.409\n",
            "Validation Loss: 0.380\n",
            "\n",
            " Epoch 4 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.337\n",
            "Validation Loss: 0.357\n",
            "\n",
            " Epoch 5 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.375\n",
            "Validation Loss: 0.447\n",
            "\n",
            " Epoch 6 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.412\n",
            "Validation Loss: 0.894\n",
            "\n",
            " Epoch 7 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.465\n",
            "Validation Loss: 0.341\n",
            "\n",
            " Epoch 8 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.320\n",
            "Validation Loss: 0.391\n",
            "\n",
            " Epoch 9 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.282\n",
            "Validation Loss: 0.406\n",
            "\n",
            " Epoch 10 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.290\n",
            "Validation Loss: 0.404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tpo2waNov_xT",
        "outputId": "f91fe66c-1659-48bf-f80d-c9ef34d904f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Predictions for Test Data"
      ],
      "metadata": {
        "id": "t-J34pODwJ7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "15oufQQQwLFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bW47nYt0pJa",
        "outputId": "fe4fc526-d57c-4093-9672-49b6f99a8c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.91      0.91        32\n",
            "           1       0.91      0.91      0.91        32\n",
            "\n",
            "    accuracy                           0.91        64\n",
            "   macro avg       0.91      0.91      0.91        64\n",
            "weighted avg       0.91      0.91      0.91        64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)\n",
        "# visualize_confusion_matrix(test_y, preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "0xjnhTbo0xga",
        "outputId": "b8591105-1bca-45b7-a14a-3b56dfdc708d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "col_0   0   1\n",
              "row_0        \n",
              "0      29   3\n",
              "1       3  29"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abb43163-264b-484d-b189-6b2f1d5be9f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abb43163-264b-484d-b189-6b2f1d5be9f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-abb43163-264b-484d-b189-6b2f1d5be9f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-abb43163-264b-484d-b189-6b2f1d5be9f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1e67888-2dd3-4109-a1b5-8a0be013ee97\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1e67888-2dd3-4109-a1b5-8a0be013ee97')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1e67888-2dd3-4109-a1b5-8a0be013ee97 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MASK MODELLING"
      ],
      "metadata": {
        "id": "FLAg1AoSkwGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import AdamW\n",
        "from transformers import BertTokenizer, BertForMaskedLM"
      ],
      "metadata": {
        "id": "0OjPYYq2DIj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_Mask = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "64yGz59vDLNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Mask = pd.read_csv('/content/Pre-training CDPtrainfileutfcopy.csv')\n",
        "df_Mask.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GBR59KWWDYRs",
        "outputId": "618e800e-8c9a-4460-9464-d6c0cdbee602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  Combined with the reality of corporate carbon ...\n",
              "1  As a science-based company, 3M uses the World ...\n",
              "2  Progress against target has been achieved thro...\n",
              "3  The target covers our whole operated container...\n",
              "4  In 2015, we set ourselves the target of saving..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a82674e-915a-4863-b285-38f6e720c004\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Combined with the reality of corporate carbon ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>As a science-based company, 3M uses the World ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Progress against target has been achieved thro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The target covers our whole operated container...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In 2015, we set ourselves the target of saving...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a82674e-915a-4863-b285-38f6e720c004')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a82674e-915a-4863-b285-38f6e720c004 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a82674e-915a-4863-b285-38f6e720c004');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3889644c-6c99-4125-aab5-bf67c5774226\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3889644c-6c99-4125-aab5-bf67c5774226')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3889644c-6c99-4125-aab5-bf67c5774226 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_Mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrvGvMInD77s",
        "outputId": "403e2bb2-03f1-40b8-b476-d937614c22d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3780"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### PREPROCESSING OF  THE DATA"
      ],
      "metadata": {
        "id": "g0u1FeqbEOAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "wz6Y5i-vEV_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for sentence in df_Mask:\n",
        "#     if len(sentence) < 50:\n",
        "#         df_Mask.drop(sentence)"
      ],
      "metadata": {
        "id": "725yy5WbEYab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing the text data"
      ],
      "metadata": {
        "id": "MVXhGu50p4As"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer_Mask(\n",
        "    df_Mask.to_csv(),\n",
        "    max_length=512,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt'\n",
        ")"
      ],
      "metadata": {
        "id": "WWAeI3IDroib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2brA3zRvRKo",
        "outputId": "bcc73d81-3266-47e0-bd2d-6f259b41ca5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs['labels'] = inputs['input_ids'].detach().clone()\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tihAT5l6vUm5",
        "outputId": "908b25f0-0818-4b2e-e34f-2b006328676c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1010,  3793,  1014,  1010,  1000,  4117,  2007,  1996,  4507,\n",
              "          1997,  5971,  6351, 11768,  1998,  4785, 10831,  1998,  6695,  1010,\n",
              "          1996,  2194,  7883,  2041,  6851,  2968,  1997,  2943,  2224,  1010,\n",
              "          7711,  1996,  2373,  8381,  1997,  2152,  1011,  2943, 15077,  3941,\n",
              "          2107,  2004,  2250, 14372,  1010,  3084,  3679, 29589,  2000,  2735,\n",
              "          2125, 14203,  2373,  6067,  1010,  1998, 15697,  2015,  2062,  4219,\n",
              "          2000,  2490,  1996,  2224,  1997, 13918,  2943,  1012,  1999, 12609,\n",
              "          1010,  1996,  2194,  4156,  1996,  2665,  2373,  2550,  2011,  1996,\n",
              "          2951,  2078,  3612,  3888,  1006,  4466,  2213,  2860,  1007,  2622,\n",
              "          1999, 19781, 14691,  3070,  2850,  2080,  2103,  1998, 19739,  2319,\n",
              "          6979,  3612,  3888,  1006,  4749,  1012,  1022, 12464,  1007,  4403,\n",
              "          2462,  2622,  1999, 22455,  6979,  2103,  2000, 16396,  6351, 11768,\n",
              "          2096,  4637,  4968, 13918,  2943,  2537,  1012,  1000,  1015,  1010,\n",
              "          1000,  2004,  1037,  2671,  1011,  2241,  2194,  1010,  1017,  2213,\n",
              "          3594,  1996,  2088,  4219,  2820,  1006, 23277,  2072,  1007,  1013,\n",
              "          2088,  2449,  2473,  2005,  9084,  2458,  1006, 25610,  6169,  2094,\n",
              "          1007,  1043, 25619,  8778,  5971,  9529,  1998,  7316,  3115,  2000,\n",
              "          2275,  1043, 25619, 15760,  7312,  7889,  1012,  2005,  2023,  3114,\n",
              "          1010,  2057,  6051,  2006,  1996,  9556,  1997,  1996,  6970,  3995,\n",
              "         23062, 26901,  5997,  2006,  4785,  2689,  1006, 12997,  9468,  1007,\n",
              "          2569,  3189,  2006,  3795, 12959,  1997,  1015,  1012,  1019,  7737,\n",
              "          2278,  2000,  2275,  2256,  3289,  1998,  4506,  1012,  2057,  1005,\n",
              "          2310,  2815,  5462,  2000,  1996,  6970,  3995, 23062, 26901,  5997,\n",
              "          2006,  4785,  2689,  1006, 12997,  9468,  1007,  2144,  2384,  1012,\n",
              "          2130,  2295,  2057,  2031,  2464,  3795, 11768,  9885,  8184,  2004,\n",
              "          1037,  2765,  1997,  1996, 15741,  3795,  2522, 17258,  1011,  2539,\n",
              "          6090,  3207,  7712,  1010,  4785,  2689,  3464,  2019, 25953,  4818,\n",
              "          5081,  1012,  2049, 14670,  2024,  6923,  1010,  1998,  2049, 10831,\n",
              "          2024,  2025,  3132,  2011,  9983,  1010,  3068,  1010,  2030,  2130,\n",
              "          2427,  1012,  2256,  6143, 15169,  7705, 23303,  2256,  4073,  2000,\n",
              "          2752,  2073,  2057,  2064,  2191,  1996,  5221,  4254,  1012,  2306,\n",
              "          1996,  2671,  2005,  4785, 14809,  1997,  2023,  7705,  1010,  2057,\n",
              "          2097,  3613,  2000,  3579,  2006,  7601,  7103,  3436,  2000, 11703,\n",
              "          2906, 11735,  4697,  3068,  1010, 29494,  3795,  4785,  7300,  1010,\n",
              "          1998,  9229,  2256,  4483, 24319,  1012,  2057,  1005,  2222,  3613,\n",
              "          2000,  3298,  4785,  7300,  1999,  2256,  3136,  1010,  1999,  2256,\n",
              "          3688,  1010,  1998,  1999,  4279,  2105,  1996,  2088,  1012,  2057,\n",
              "          2097,  2224,  1996, 12997,  9468, 12098,  2575,  4785,  2689, 25682,\n",
              "          1024,  1996,  3558,  2671,  3978,  3189,  2000, 12367,  2256,  4785,\n",
              "          5656,  1012,  1999,  2325,  1010,  1017,  2213,  2275,  1037,  3125,\n",
              "          2000,  5676,  1043, 25619, 11768,  2024,  2012,  2560,  2753,  1003,\n",
              "          2917,  2256,  2526, 26163,  2011, 16798,  2629,  1012,  1017,  2213,\n",
              "          1005,  1055,  2047,  8426,  1006,  2623,  1999, 25682,  1007,  2003,\n",
              "          2000,  5547,  9531,  1015,  1998,  1016,  3006,  1011,  2241,  1043,\n",
              "         25619, 11768,  2013,  2256, 10476, 26163,  2011,  2012,  2560,  2753,\n",
              "          1003,  2011, 18540,  2692,  1010,  3770,  1003,  2011, 19627,  2692,\n",
              "          1010,  1998,  2022,  2531,  1003,  6351,  8699,  1999,  2256,  3136,\n",
              "          2011, 16327,  2692,  1012,  2023,  2003,  1037,  3706,  3125,  1012,\n",
              "          1996,  2795,  2682,  7127,  1996,  4539,  2005,  1996,  2034,  3357,\n",
              "          1012,  1000,  1016,  1010,  1000,  5082,  2114,  4539,  2038,  2042,\n",
              "          4719,  2083,  1037,  5257,  1997,  4722, 11107,  1998,  2083,  1996,\n",
              "          5301,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  101,  1010,  3793,  1014,  1010,  1000,  4117,  2007,  1996,  4507,\n",
              "          1997,  5971,  6351, 11768,  1998,  4785, 10831,  1998,  6695,  1010,\n",
              "          1996,  2194,  7883,  2041,  6851,  2968,  1997,  2943,  2224,  1010,\n",
              "          7711,  1996,  2373,  8381,  1997,  2152,  1011,  2943, 15077,  3941,\n",
              "          2107,  2004,  2250, 14372,  1010,  3084,  3679, 29589,  2000,  2735,\n",
              "          2125, 14203,  2373,  6067,  1010,  1998, 15697,  2015,  2062,  4219,\n",
              "          2000,  2490,  1996,  2224,  1997, 13918,  2943,  1012,  1999, 12609,\n",
              "          1010,  1996,  2194,  4156,  1996,  2665,  2373,  2550,  2011,  1996,\n",
              "          2951,  2078,  3612,  3888,  1006,  4466,  2213,  2860,  1007,  2622,\n",
              "          1999, 19781, 14691,  3070,  2850,  2080,  2103,  1998, 19739,  2319,\n",
              "          6979,  3612,  3888,  1006,  4749,  1012,  1022, 12464,  1007,  4403,\n",
              "          2462,  2622,  1999, 22455,  6979,  2103,  2000, 16396,  6351, 11768,\n",
              "          2096,  4637,  4968, 13918,  2943,  2537,  1012,  1000,  1015,  1010,\n",
              "          1000,  2004,  1037,  2671,  1011,  2241,  2194,  1010,  1017,  2213,\n",
              "          3594,  1996,  2088,  4219,  2820,  1006, 23277,  2072,  1007,  1013,\n",
              "          2088,  2449,  2473,  2005,  9084,  2458,  1006, 25610,  6169,  2094,\n",
              "          1007,  1043, 25619,  8778,  5971,  9529,  1998,  7316,  3115,  2000,\n",
              "          2275,  1043, 25619, 15760,  7312,  7889,  1012,  2005,  2023,  3114,\n",
              "          1010,  2057,  6051,  2006,  1996,  9556,  1997,  1996,  6970,  3995,\n",
              "         23062, 26901,  5997,  2006,  4785,  2689,  1006, 12997,  9468,  1007,\n",
              "          2569,  3189,  2006,  3795, 12959,  1997,  1015,  1012,  1019,  7737,\n",
              "          2278,  2000,  2275,  2256,  3289,  1998,  4506,  1012,  2057,  1005,\n",
              "          2310,  2815,  5462,  2000,  1996,  6970,  3995, 23062, 26901,  5997,\n",
              "          2006,  4785,  2689,  1006, 12997,  9468,  1007,  2144,  2384,  1012,\n",
              "          2130,  2295,  2057,  2031,  2464,  3795, 11768,  9885,  8184,  2004,\n",
              "          1037,  2765,  1997,  1996, 15741,  3795,  2522, 17258,  1011,  2539,\n",
              "          6090,  3207,  7712,  1010,  4785,  2689,  3464,  2019, 25953,  4818,\n",
              "          5081,  1012,  2049, 14670,  2024,  6923,  1010,  1998,  2049, 10831,\n",
              "          2024,  2025,  3132,  2011,  9983,  1010,  3068,  1010,  2030,  2130,\n",
              "          2427,  1012,  2256,  6143, 15169,  7705, 23303,  2256,  4073,  2000,\n",
              "          2752,  2073,  2057,  2064,  2191,  1996,  5221,  4254,  1012,  2306,\n",
              "          1996,  2671,  2005,  4785, 14809,  1997,  2023,  7705,  1010,  2057,\n",
              "          2097,  3613,  2000,  3579,  2006,  7601,  7103,  3436,  2000, 11703,\n",
              "          2906, 11735,  4697,  3068,  1010, 29494,  3795,  4785,  7300,  1010,\n",
              "          1998,  9229,  2256,  4483, 24319,  1012,  2057,  1005,  2222,  3613,\n",
              "          2000,  3298,  4785,  7300,  1999,  2256,  3136,  1010,  1999,  2256,\n",
              "          3688,  1010,  1998,  1999,  4279,  2105,  1996,  2088,  1012,  2057,\n",
              "          2097,  2224,  1996, 12997,  9468, 12098,  2575,  4785,  2689, 25682,\n",
              "          1024,  1996,  3558,  2671,  3978,  3189,  2000, 12367,  2256,  4785,\n",
              "          5656,  1012,  1999,  2325,  1010,  1017,  2213,  2275,  1037,  3125,\n",
              "          2000,  5676,  1043, 25619, 11768,  2024,  2012,  2560,  2753,  1003,\n",
              "          2917,  2256,  2526, 26163,  2011, 16798,  2629,  1012,  1017,  2213,\n",
              "          1005,  1055,  2047,  8426,  1006,  2623,  1999, 25682,  1007,  2003,\n",
              "          2000,  5547,  9531,  1015,  1998,  1016,  3006,  1011,  2241,  1043,\n",
              "         25619, 11768,  2013,  2256, 10476, 26163,  2011,  2012,  2560,  2753,\n",
              "          1003,  2011, 18540,  2692,  1010,  3770,  1003,  2011, 19627,  2692,\n",
              "          1010,  1998,  2022,  2531,  1003,  6351,  8699,  1999,  2256,  3136,\n",
              "          2011, 16327,  2692,  1012,  2023,  2003,  1037,  3706,  3125,  1012,\n",
              "          1996,  2795,  2682,  7127,  1996,  4539,  2005,  1996,  2034,  3357,\n",
              "          1012,  1000,  1016,  1010,  1000,  5082,  2114,  4539,  2038,  2042,\n",
              "          4719,  2083,  1037,  5257,  1997,  4722, 11107,  1998,  2083,  1996,\n",
              "          5301,   102]])}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masking the input_ids"
      ],
      "metadata": {
        "id": "YE2ss4lXxATF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(inputs['input_ids'].shape)\n"
      ],
      "metadata": {
        "id": "hpVcHP-ExBME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K36-l26ryu3W",
        "outputId": "857a2ce5-996c-45f2-99ca-b891defef5d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a random tensor of float values.\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFSrfEmezbpO",
        "outputId": "f2de3a6b-8093-4a5a-87d5-3712581c81d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.8007e-01, 2.9526e-02, 7.1301e-01, 2.9950e-01, 3.1698e-02, 9.1627e-01,\n",
              "         5.5208e-01, 5.8033e-02, 6.5962e-01, 1.4581e-01, 2.1655e-01, 3.4455e-02,\n",
              "         6.0180e-01, 4.4106e-01, 9.6756e-01, 5.5546e-01, 3.0965e-01, 2.6306e-01,\n",
              "         4.8776e-01, 9.8683e-01, 4.8247e-01, 1.6594e-01, 7.5967e-01, 1.0089e-01,\n",
              "         7.8124e-01, 6.7216e-01, 9.2820e-01, 6.0957e-01, 8.3558e-01, 7.2606e-01,\n",
              "         4.3962e-01, 7.7929e-01, 4.9729e-01, 3.4866e-01, 4.1676e-01, 2.8329e-01,\n",
              "         1.3423e-01, 2.6659e-01, 4.7036e-01, 3.6063e-01, 5.9495e-01, 9.6829e-01,\n",
              "         1.7466e-01, 5.9643e-01, 6.3762e-02, 6.5236e-02, 4.3054e-02, 4.1632e-01,\n",
              "         1.9473e-01, 6.0556e-01, 3.9121e-02, 8.5205e-01, 7.7815e-01, 2.2039e-01,\n",
              "         9.4445e-01, 6.1825e-01, 2.3980e-01, 2.1990e-01, 8.4198e-01, 9.9151e-01,\n",
              "         8.6634e-01, 1.7206e-01, 1.8864e-03, 8.6265e-01, 8.9080e-01, 1.9049e-01,\n",
              "         9.1233e-01, 3.3650e-01, 4.2247e-01, 8.2410e-01, 1.5590e-01, 4.6224e-01,\n",
              "         7.2568e-01, 2.1293e-01, 8.0850e-01, 1.4118e-01, 4.1826e-01, 5.9986e-01,\n",
              "         6.5846e-01, 3.9708e-01, 8.9976e-02, 6.3592e-01, 5.8722e-01, 5.2124e-01,\n",
              "         5.0681e-01, 5.3396e-01, 7.3229e-01, 5.6791e-01, 8.4014e-01, 6.5370e-01,\n",
              "         1.8453e-01, 7.5815e-01, 6.3773e-01, 9.2337e-01, 2.0098e-01, 1.4342e-01,\n",
              "         6.2282e-01, 9.6052e-01, 3.1908e-01, 7.5269e-01, 3.8025e-01, 9.2767e-01,\n",
              "         8.1417e-01, 1.3610e-01, 9.4541e-01, 7.9011e-02, 5.3074e-02, 1.9484e-01,\n",
              "         2.0387e-01, 7.9869e-01, 1.1908e-01, 1.6988e-01, 5.7798e-02, 1.5757e-01,\n",
              "         2.4003e-04, 1.4446e-01, 3.1488e-01, 2.8137e-01, 8.9105e-01, 3.8963e-01,\n",
              "         6.8853e-01, 4.5489e-01, 5.0057e-01, 1.5453e-01, 1.7160e-02, 6.7321e-01,\n",
              "         8.9812e-01, 3.8006e-01, 6.2750e-01, 1.8383e-01, 8.6887e-01, 2.4873e-01,\n",
              "         2.8273e-01, 6.0625e-01, 2.5633e-02, 6.0068e-01, 1.8704e-01, 8.6512e-01,\n",
              "         4.5529e-01, 3.6393e-01, 8.2544e-03, 4.7565e-02, 6.9276e-01, 2.5489e-01,\n",
              "         2.5410e-01, 4.9609e-01, 2.6005e-01, 7.2964e-01, 2.2929e-01, 6.3865e-01,\n",
              "         7.0940e-01, 3.7652e-01, 4.9324e-01, 3.0686e-01, 1.4429e-01, 8.7160e-01,\n",
              "         2.5427e-01, 4.6670e-01, 2.2934e-01, 2.1119e-01, 7.1403e-01, 2.6243e-02,\n",
              "         5.0392e-01, 9.4385e-01, 2.8754e-01, 6.2098e-01, 6.6875e-01, 1.7986e-01,\n",
              "         1.0077e-01, 6.2268e-01, 1.0501e-01, 5.3447e-01, 8.6504e-01, 6.1304e-01,\n",
              "         1.7689e-01, 5.8505e-01, 5.3480e-01, 5.2157e-01, 4.7018e-01, 3.3619e-01,\n",
              "         1.0370e-01, 4.2328e-01, 1.3965e-01, 5.1325e-01, 6.6255e-01, 1.1680e-02,\n",
              "         4.3614e-01, 6.5829e-01, 6.3250e-01, 9.7623e-01, 3.0816e-01, 9.7899e-01,\n",
              "         4.9752e-01, 4.6446e-01, 9.6560e-01, 3.8931e-01, 9.9441e-01, 8.1261e-01,\n",
              "         3.5412e-01, 6.8500e-02, 3.0648e-01, 2.1701e-02, 9.4700e-01, 6.4555e-01,\n",
              "         7.0524e-02, 2.8515e-01, 5.4701e-01, 6.6174e-01, 1.4471e-01, 6.4585e-01,\n",
              "         9.6049e-01, 3.2318e-01, 9.6979e-01, 1.8236e-02, 1.9628e-01, 4.6192e-01,\n",
              "         2.0434e-01, 1.3372e-01, 4.9532e-01, 5.2426e-01, 2.7763e-01, 9.8856e-01,\n",
              "         1.9993e-01, 2.2088e-01, 1.6158e-01, 4.0195e-01, 7.3581e-01, 7.4526e-01,\n",
              "         4.9961e-01, 3.8346e-01, 8.9832e-01, 9.2076e-01, 9.4409e-01, 2.8038e-01,\n",
              "         6.3019e-01, 3.5934e-01, 3.4000e-01, 8.7832e-01, 5.1040e-02, 9.9007e-01,\n",
              "         5.8981e-01, 1.7140e-01, 8.5568e-01, 3.0079e-01, 1.1911e-01, 7.2455e-01,\n",
              "         4.4230e-01, 2.4468e-01, 3.3224e-01, 3.2984e-01, 5.8583e-02, 1.8492e-01,\n",
              "         9.4086e-01, 9.4668e-01, 1.1341e-01, 4.8825e-01, 6.6410e-01, 5.3358e-01,\n",
              "         5.5049e-01, 7.0552e-01, 8.7285e-01, 3.7419e-02, 6.1030e-01, 3.0828e-01,\n",
              "         4.1071e-02, 7.6184e-01, 5.7294e-02, 7.3102e-01, 3.2267e-01, 2.7686e-01,\n",
              "         4.0693e-01, 4.3486e-01, 7.7057e-02, 3.2373e-01, 3.8868e-01, 8.0346e-01,\n",
              "         4.5360e-01, 3.4606e-01, 6.4679e-01, 6.6466e-01, 1.5118e-01, 5.6598e-01,\n",
              "         7.1682e-01, 4.9004e-01, 9.9781e-01, 1.0309e-02, 2.4348e-01, 6.1149e-01,\n",
              "         7.9771e-01, 4.9581e-01, 1.9588e-01, 6.9677e-01, 1.3844e-01, 2.9643e-01,\n",
              "         6.6405e-01, 1.4201e-01, 4.0062e-02, 3.1218e-02, 7.2283e-01, 2.1353e-01,\n",
              "         3.5972e-01, 1.4026e-01, 6.5589e-01, 3.1705e-01, 2.2481e-02, 6.0565e-01,\n",
              "         6.1793e-01, 2.4850e-02, 4.8817e-01, 2.9044e-01, 2.2972e-01, 5.5699e-01,\n",
              "         4.7681e-01, 4.7433e-01, 4.0313e-01, 2.5724e-01, 6.3136e-01, 5.7500e-01,\n",
              "         8.0527e-03, 1.1206e-02, 5.3633e-01, 2.3020e-02, 8.7670e-01, 1.0762e-01,\n",
              "         2.6365e-01, 1.4833e-01, 6.5881e-02, 9.4321e-01, 8.6154e-01, 3.1362e-02,\n",
              "         4.2519e-01, 8.3698e-01, 2.6295e-01, 3.5362e-01, 9.5625e-01, 1.9557e-01,\n",
              "         5.6423e-02, 2.2745e-01, 5.6745e-01, 1.1327e-01, 1.8290e-02, 8.1248e-01,\n",
              "         5.4127e-01, 2.1597e-01, 7.9754e-02, 2.6415e-01, 4.1988e-01, 2.6515e-01,\n",
              "         7.9996e-01, 2.9152e-01, 7.5626e-01, 7.1843e-01, 8.4121e-01, 4.4285e-01,\n",
              "         7.2380e-01, 8.9908e-01, 3.6502e-01, 3.4634e-01, 3.0983e-01, 3.9200e-01,\n",
              "         6.1277e-01, 5.9114e-01, 5.6289e-01, 7.1570e-02, 9.5537e-01, 5.3775e-01,\n",
              "         2.8425e-01, 5.6606e-01, 9.3245e-01, 7.1493e-01, 5.5164e-01, 4.7469e-01,\n",
              "         8.0159e-01, 7.7033e-01, 4.3510e-01, 7.5345e-01, 9.6932e-01, 4.8849e-01,\n",
              "         8.7159e-01, 5.5861e-01, 2.7119e-01, 3.8851e-02, 2.0390e-01, 7.0905e-02,\n",
              "         1.2205e-01, 1.9040e-01, 9.5381e-01, 2.9192e-01, 2.2085e-01, 8.4843e-01,\n",
              "         6.7710e-01, 5.1731e-01, 5.1741e-01, 2.1689e-01, 6.3157e-01, 2.4644e-01,\n",
              "         5.6539e-01, 1.8595e-01, 9.8592e-01, 5.2388e-01, 2.4178e-02, 1.7785e-01,\n",
              "         8.7717e-01, 2.0402e-01, 5.8768e-01, 2.5605e-01, 6.7746e-01, 2.6053e-01,\n",
              "         7.7630e-02, 8.7472e-01, 8.6958e-01, 5.8136e-01, 9.7289e-01, 1.8691e-03,\n",
              "         5.8179e-01, 9.5019e-01, 9.4825e-01, 6.1478e-02, 6.6247e-01, 6.0912e-01,\n",
              "         7.2151e-01, 6.0667e-01, 9.4707e-01, 5.7260e-01, 2.7049e-01, 2.4043e-01,\n",
              "         2.7384e-01, 4.7152e-01, 9.2335e-01, 9.0799e-01, 6.0907e-01, 5.0135e-01,\n",
              "         5.8605e-01, 7.6667e-01, 1.2239e-01, 3.4476e-01, 9.2859e-01, 9.8465e-01,\n",
              "         9.4182e-01, 4.3195e-01, 7.6509e-01, 1.2978e-03, 7.9401e-01, 4.0551e-01,\n",
              "         8.9240e-01, 8.1539e-04, 7.6895e-01, 7.2058e-01, 4.6039e-01, 6.6477e-01,\n",
              "         2.3310e-01, 6.9982e-01, 2.2858e-01, 5.7850e-01, 1.1389e-01, 1.3262e-01,\n",
              "         3.5227e-01, 2.5671e-01, 7.9916e-01, 1.3415e-01, 7.6829e-01, 8.5330e-01,\n",
              "         3.8493e-01, 9.4073e-01, 4.1264e-01, 4.7218e-01, 2.3583e-01, 7.3850e-01,\n",
              "         1.7274e-01, 3.8893e-01, 7.4656e-01, 6.0250e-01, 8.4319e-01, 4.4054e-01,\n",
              "         9.1433e-01, 3.4048e-01, 1.4206e-01, 5.1229e-01, 3.2237e-01, 4.9616e-01,\n",
              "         5.7881e-01, 9.4076e-01, 1.8298e-01, 4.1682e-01, 5.4719e-01, 7.7471e-03,\n",
              "         7.4233e-01, 7.0211e-01, 4.1359e-01, 6.6129e-01, 1.3950e-01, 8.5800e-01,\n",
              "         8.0681e-01, 1.4372e-01, 7.7394e-01, 3.7014e-01, 2.5415e-01, 4.3717e-02,\n",
              "         8.5955e-01, 2.1449e-01, 2.5177e-01, 1.3596e-01, 9.3250e-01, 2.3789e-01,\n",
              "         3.1404e-01, 3.5766e-01, 8.2623e-01, 3.3656e-01, 2.4270e-01, 5.7982e-01,\n",
              "         8.1727e-01, 6.8224e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a mask tensor of float values ranging from 0 to 1 and avoiding special tokens\n",
        "masked_tensor = (random_tensor < 0.15)*(inputs['input_ids'] != 101)*(inputs['input_ids'] != 102)*(inputs['input_ids'] != 0)\n",
        "\n",
        "# where 101 = classification tokens which is a special token\n",
        "# 101 is the padding tokens\n",
        "# 0.15 implies we are masking 15% of the other tokens though we can change to 1 for full masking of the other tokens."
      ],
      "metadata": {
        "id": "nmPOBTzCzmE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQbOb74i9vBA",
        "outputId": "415a83df-fe39-46ff-daca-4886306db61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True, False, False,  True, False, False,  True, False,  True,\n",
              "         False,  True, False, False, False, False, False, False, False, False,\n",
              "         False, False, False,  True, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False,  True, False, False, False,\n",
              "         False, False, False, False,  True,  True,  True, False, False, False,\n",
              "          True, False, False, False, False, False, False, False, False, False,\n",
              "         False, False,  True, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False,  True, False, False, False, False,\n",
              "          True, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False,  True, False, False, False, False,\n",
              "         False, False, False,  True, False,  True,  True, False, False, False,\n",
              "          True, False,  True, False,  True,  True, False, False, False, False,\n",
              "         False, False, False, False,  True, False, False, False, False, False,\n",
              "         False, False, False, False,  True, False, False, False, False, False,\n",
              "          True,  True, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False,  True, False, False, False, False, False,\n",
              "         False,  True, False, False, False, False, False, False,  True, False,\n",
              "          True, False, False, False, False, False, False, False, False, False,\n",
              "          True, False,  True, False, False,  True, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False,  True,\n",
              "         False,  True, False, False,  True, False, False, False,  True, False,\n",
              "         False, False, False,  True, False, False, False,  True, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False,  True, False,\n",
              "         False, False, False, False,  True, False, False, False, False, False,\n",
              "          True, False, False, False,  True, False, False, False, False, False,\n",
              "         False,  True, False, False,  True, False,  True, False, False, False,\n",
              "         False, False,  True, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False,  True, False, False, False, False,\n",
              "         False, False,  True, False, False,  True,  True,  True, False, False,\n",
              "         False,  True, False, False,  True, False, False,  True, False, False,\n",
              "         False, False, False, False, False, False, False, False,  True,  True,\n",
              "         False,  True, False,  True, False,  True,  True, False, False,  True,\n",
              "         False, False, False, False, False, False,  True, False, False,  True,\n",
              "          True, False, False, False,  True, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False,  True, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False,  True, False,  True,  True, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "          True, False, False, False, False, False, False, False,  True, False,\n",
              "         False, False, False,  True, False, False, False,  True, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False,  True, False, False, False, False, False,\n",
              "         False,  True, False, False, False,  True, False, False, False, False,\n",
              "         False, False, False, False,  True,  True, False, False, False,  True,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False,  True, False, False, False,\n",
              "         False, False, False, False, False,  True, False, False, False, False,\n",
              "          True, False, False,  True, False, False, False,  True, False, False,\n",
              "         False,  True, False, False, False, False, False, False, False, False,\n",
              "         False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let us retrieve all the indices within our tokens that are true.\n",
        "\n",
        "nonzeros_indices = []\n",
        "for i in range(len(inputs['input_ids'])):\n",
        "  masked_tensor[i].nonzero()"
      ],
      "metadata": {
        "id": "zy_Jn9ID-j42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_tensor[i].nonzero()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH240OI5A87H",
        "outputId": "a6daedb3-38b6-4e8e-e6b3-f8a5a63f9c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1],\n",
              "        [  4],\n",
              "        [  7],\n",
              "        [  9],\n",
              "        [ 11],\n",
              "        [ 23],\n",
              "        [ 36],\n",
              "        [ 44],\n",
              "        [ 45],\n",
              "        [ 46],\n",
              "        [ 50],\n",
              "        [ 62],\n",
              "        [ 75],\n",
              "        [ 80],\n",
              "        [ 95],\n",
              "        [103],\n",
              "        [105],\n",
              "        [106],\n",
              "        [110],\n",
              "        [112],\n",
              "        [114],\n",
              "        [115],\n",
              "        [124],\n",
              "        [134],\n",
              "        [140],\n",
              "        [141],\n",
              "        [154],\n",
              "        [161],\n",
              "        [168],\n",
              "        [170],\n",
              "        [180],\n",
              "        [182],\n",
              "        [185],\n",
              "        [199],\n",
              "        [201],\n",
              "        [204],\n",
              "        [208],\n",
              "        [213],\n",
              "        [217],\n",
              "        [238],\n",
              "        [244],\n",
              "        [250],\n",
              "        [254],\n",
              "        [261],\n",
              "        [264],\n",
              "        [266],\n",
              "        [272],\n",
              "        [285],\n",
              "        [292],\n",
              "        [295],\n",
              "        [296],\n",
              "        [297],\n",
              "        [301],\n",
              "        [304],\n",
              "        [307],\n",
              "        [318],\n",
              "        [319],\n",
              "        [321],\n",
              "        [323],\n",
              "        [325],\n",
              "        [326],\n",
              "        [329],\n",
              "        [336],\n",
              "        [339],\n",
              "        [340],\n",
              "        [344],\n",
              "        [363],\n",
              "        [381],\n",
              "        [383],\n",
              "        [384],\n",
              "        [400],\n",
              "        [408],\n",
              "        [413],\n",
              "        [417],\n",
              "        [434],\n",
              "        [441],\n",
              "        [445],\n",
              "        [454],\n",
              "        [455],\n",
              "        [459],\n",
              "        [476],\n",
              "        [485],\n",
              "        [490],\n",
              "        [493],\n",
              "        [497],\n",
              "        [501]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the tokens that are true needs to be flattended and for that we invoke out torch library\n",
        "\n",
        "torch.flatten(masked_tensor[i].nonzero())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1C01JFMBUUv",
        "outputId": "64db7449-5387-4fd1-f9ad-11cc6338832b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1,   4,   7,   9,  11,  23,  36,  44,  45,  46,  50,  62,  75,  80,\n",
              "         95, 103, 105, 106, 110, 112, 114, 115, 124, 134, 140, 141, 154, 161,\n",
              "        168, 170, 180, 182, 185, 199, 201, 204, 208, 213, 217, 238, 244, 250,\n",
              "        254, 261, 264, 266, 272, 285, 292, 295, 296, 297, 301, 304, 307, 318,\n",
              "        319, 321, 323, 325, 326, 329, 336, 339, 340, 344, 363, 381, 383, 384,\n",
              "        400, 408, 413, 417, 434, 441, 445, 454, 455, 459, 476, 485, 490, 493,\n",
              "        497, 501])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the flattended tokens needs to be converted to a list and for that we invoke the .to_list attribute so that it allows us to store values\n",
        "# of mask indices.\n",
        "nonzeros_indices.append(torch.flatten(masked_tensor[i].nonzero()).tolist())\n"
      ],
      "metadata": {
        "id": "ffGnXxDHBpeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets now have a look at what we have appended\n",
        "nonzeros_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcZ6CpjpCQvx",
        "outputId": "76e3a440-c7e2-48ff-c1ec-bf073dfbf8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1,\n",
              "  4,\n",
              "  7,\n",
              "  9,\n",
              "  11,\n",
              "  23,\n",
              "  36,\n",
              "  44,\n",
              "  45,\n",
              "  46,\n",
              "  50,\n",
              "  62,\n",
              "  75,\n",
              "  80,\n",
              "  95,\n",
              "  103,\n",
              "  105,\n",
              "  106,\n",
              "  110,\n",
              "  112,\n",
              "  114,\n",
              "  115,\n",
              "  124,\n",
              "  134,\n",
              "  140,\n",
              "  141,\n",
              "  154,\n",
              "  161,\n",
              "  168,\n",
              "  170,\n",
              "  180,\n",
              "  182,\n",
              "  185,\n",
              "  199,\n",
              "  201,\n",
              "  204,\n",
              "  208,\n",
              "  213,\n",
              "  217,\n",
              "  238,\n",
              "  244,\n",
              "  250,\n",
              "  254,\n",
              "  261,\n",
              "  264,\n",
              "  266,\n",
              "  272,\n",
              "  285,\n",
              "  292,\n",
              "  295,\n",
              "  296,\n",
              "  297,\n",
              "  301,\n",
              "  304,\n",
              "  307,\n",
              "  318,\n",
              "  319,\n",
              "  321,\n",
              "  323,\n",
              "  325,\n",
              "  326,\n",
              "  329,\n",
              "  336,\n",
              "  339,\n",
              "  340,\n",
              "  344,\n",
              "  363,\n",
              "  381,\n",
              "  383,\n",
              "  384,\n",
              "  400,\n",
              "  408,\n",
              "  413,\n",
              "  417,\n",
              "  434,\n",
              "  441,\n",
              "  445,\n",
              "  454,\n",
              "  455,\n",
              "  459,\n",
              "  476,\n",
              "  485,\n",
              "  490,\n",
              "  493,\n",
              "  497,\n",
              "  501]]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let us now replace the true indiced values with the 103 ids i.e. the masked token ids\n",
        "\n",
        "for i in range(len(inputs['input_ids'])):\n",
        "  inputs['input_ids'][i, nonzeros_indices[i]] = 103"
      ],
      "metadata": {
        "id": "_qNwXhvODTC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best practice is always to have a look at our dictionary how it looks\n",
        "# we will see that wherever there was true, we now have 103 (masked token) instead of the actual indices\n",
        "\n",
        "inputs['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC0aBjoiEzx8",
        "outputId": "5b109926-43f6-481f-e0b2-e3118543bed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,   103,  3793,  1014,   103,  1000,  4117,   103,  1996,   103,\n",
              "          1997,   103,  6351, 11768,  1998,  4785, 10831,  1998,  6695,  1010,\n",
              "          1996,  2194,  7883,   103,  6851,  2968,  1997,  2943,  2224,  1010,\n",
              "          7711,  1996,  2373,  8381,  1997,  2152,   103,  2943, 15077,  3941,\n",
              "          2107,  2004,  2250, 14372,   103,   103,   103, 29589,  2000,  2735,\n",
              "           103, 14203,  2373,  6067,  1010,  1998, 15697,  2015,  2062,  4219,\n",
              "          2000,  2490,   103,  2224,  1997, 13918,  2943,  1012,  1999, 12609,\n",
              "          1010,  1996,  2194,  4156,  1996,   103,  2373,  2550,  2011,  1996,\n",
              "           103,  2078,  3612,  3888,  1006,  4466,  2213,  2860,  1007,  2622,\n",
              "          1999, 19781, 14691,  3070,  2850,   103,  2103,  1998, 19739,  2319,\n",
              "          6979,  3612,  3888,   103,  4749,   103,   103, 12464,  1007,  4403,\n",
              "           103,  2622,   103, 22455,   103,   103,  2000, 16396,  6351, 11768,\n",
              "          2096,  4637,  4968, 13918,   103,  2537,  1012,  1000,  1015,  1010,\n",
              "          1000,  2004,  1037,  2671,   103,  2241,  2194,  1010,  1017,  2213,\n",
              "           103,   103,  2088,  4219,  2820,  1006, 23277,  2072,  1007,  1013,\n",
              "          2088,  2449,  2473,  2005,   103,  2458,  1006, 25610,  6169,  2094,\n",
              "          1007,   103, 25619,  8778,  5971,  9529,  1998,  7316,   103,  2000,\n",
              "           103,  1043, 25619, 15760,  7312,  7889,  1012,  2005,  2023,  3114,\n",
              "           103,  2057,   103,  2006,  1996,   103,  1997,  1996,  6970,  3995,\n",
              "         23062, 26901,  5997,  2006,  4785,  2689,  1006, 12997,  9468,   103,\n",
              "          2569,   103,  2006,  3795,   103,  1997,  1015,  1012,   103,  7737,\n",
              "          2278,  2000,  2275,   103,  3289,  1998,  4506,   103,  2057,  1005,\n",
              "          2310,  2815,  5462,  2000,  1996,  6970,  3995, 23062, 26901,  5997,\n",
              "          2006,  4785,  2689,  1006, 12997,  9468,  1007,  2144,   103,  1012,\n",
              "          2130,  2295,  2057,  2031,   103,  3795, 11768,  9885,  8184,  2004,\n",
              "           103,  2765,  1997,  1996,   103,  3795,  2522, 17258,  1011,  2539,\n",
              "          6090,   103,  7712,  1010,   103,  2689,   103,  2019, 25953,  4818,\n",
              "          5081,  1012,   103, 14670,  2024,  6923,  1010,  1998,  2049, 10831,\n",
              "          2024,  2025,  3132,  2011,  9983,   103,  3068,  1010,  2030,  2130,\n",
              "          2427,  1012,   103,  6143, 15169,   103,   103,   103,  4073,  2000,\n",
              "          2752,   103,  2057,  2064,   103,  1996,  5221,   103,  1012,  2306,\n",
              "          1996,  2671,  2005,  4785, 14809,  1997,  2023,  7705,   103,   103,\n",
              "          2097,   103,  2000,   103,  2006,   103,   103,  3436,  2000,   103,\n",
              "          2906, 11735,  4697,  3068,  1010, 29494,   103,  4785,  7300,   103,\n",
              "           103,  9229,  2256,  4483,   103,  1012,  2057,  1005,  2222,  3613,\n",
              "          2000,  3298,  4785,  7300,  1999,  2256,  3136,  1010,  1999,  2256,\n",
              "          3688,  1010,  1998,   103,  4279,  2105,  1996,  2088,  1012,  2057,\n",
              "          2097,  2224,  1996, 12997,  9468, 12098,  2575,  4785,  2689, 25682,\n",
              "          1024,   103,  3558,   103,   103,  3189,  2000, 12367,  2256,  4785,\n",
              "          5656,  1012,  1999,  2325,  1010,  1017,  2213,  2275,  1037,  3125,\n",
              "           103,  5676,  1043, 25619, 11768,  2024,  2012,  2560,   103,  1003,\n",
              "          2917,  2256,  2526,   103,  2011, 16798,  2629,   103,  1017,  2213,\n",
              "          1005,  1055,  2047,  8426,  1006,  2623,  1999, 25682,  1007,  2003,\n",
              "          2000,  5547,  9531,  1015,   103,  1016,  3006,  1011,  2241,  1043,\n",
              "         25619,   103,  2013,  2256, 10476,   103,  2011,  2012,  2560,  2753,\n",
              "          1003,  2011, 18540,  2692,   103,   103,  1003,  2011, 19627,   103,\n",
              "          1010,  1998,  2022,  2531,  1003,  6351,  8699,  1999,  2256,  3136,\n",
              "          2011, 16327,  2692,  1012,  2023,  2003,   103,  3706,  3125,  1012,\n",
              "          1996,  2795,  2682,  7127,  1996,   103,  2005,  1996,  2034,  3357,\n",
              "           103,  1000,  1016,   103,  1000,  5082,  2114,   103,  2038,  2042,\n",
              "          4719,   103,  1037,  5257,  1997,  4722, 11107,  1998,  2083,  1996,\n",
              "          5301,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to convert the tensors now to a pytorch data object so that we can be able to process the tensors into a pytoch data loader\n",
        "\n"
      ],
      "metadata": {
        "id": "_PTvtn76FTWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Dataset"
      ],
      "metadata": {
        "id": "eSj69_7CGAvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to convert the tensors now to a pytorch data object so that we can be able to process the tensors into a pytoch data loader\n",
        "\n",
        "class MaskDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input_ids = self.encodings\n",
        "        ['input_ids'][index]\n",
        "        labels = self.encodings['labels'][index]\n",
        "        attention_mask = self.encodings['attention_mask'][index]\n",
        "        token_type_ids = self.encodings['token_type_ids'][index]\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'labels': labels,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids\n",
        "        }"
      ],
      "metadata": {
        "id": "JUdxXQHUGLFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining an instance of the data class passing the input of the encodings\n",
        "\n",
        "dataset = MaskDataset(inputs)"
      ],
      "metadata": {
        "id": "IgikmpV6IIrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOsWELkFI2_P",
        "outputId": "ebc40d26-ddb0-4af7-a61b-10c43bd76fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.MaskDataset at 0x7fccc0633280>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA LOADER"
      ],
      "metadata": {
        "id": "W98Opec1JALw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=16, # depends on how much cpu/gpu your computer has\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "1Rc2zDcXIbHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let us define the device we will be training on and assign it to gpu unless in the case there is no gpu then it switches to cpu\n",
        "device_Mask = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device_Mask\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyFzM7DkJuPH",
        "outputId": "92f628d2-d1d2-4a32-e31e-8058367c72f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let us us now call our model from the huggingface and push it to our graphics device\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "model_Mask = pipeline('fill-mask', model='distilroberta-base')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sed24otgJ-6d",
        "outputId": "a66b18c9-b8f3-4f93-f7b4-50f5f30edd56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_Mask.to(device_Mask)"
      ],
      "metadata": {
        "id": "GJa7gF1V0-f0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}